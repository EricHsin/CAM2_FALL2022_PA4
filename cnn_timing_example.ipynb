{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU acceleration available!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import time\n",
    "### \n",
    "### Note: You must go to Runtime -> Change Runtime Type -> Select GPU for GPU acceleration\n",
    "if torch.cuda.is_available():\n",
    "  print(\"GPU acceleration available!\")\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  print(\"Using CPU - no GPU acceleration available\")\n",
    "  ### Set default tensor type to CPU\n",
    "  device = torch.device('cpu')\n",
    "### Neural Network Model\n",
    "### MNIST images are 1 channel 28x28 images\n",
    "class MNIST_CNN( torch.nn.Module ):\n",
    "  # Constructor\n",
    "  def __init__(self):\n",
    "    # Invoke constructor of nn.Model\n",
    "    super(MNIST_CNN, self).__init__()\n",
    "    # Initialize layers of network\n",
    "    self.conv1\t  = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn1\t  = torch.nn.BatchNorm2d(16)\n",
    "    self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.conv2\t  = torch.nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn2\t  = torch.nn.BatchNorm2d(24)\n",
    "    self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    self.conv3\t  = torch.nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn3\t  = torch.nn.BatchNorm2d(32)\n",
    "    self.conv4\t  = torch.nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn4\t  = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "    self.conv5\t  = torch.nn.Conv2d(in_channels=32, out_channels=48, kernel_size=3, stride=1, padding=1)\n",
    "    self.bn5\t  = torch.nn.BatchNorm2d(48)\n",
    "\n",
    "    # Final Output Layers\n",
    "    # Flatten 1x28x28 to 1x768\n",
    "    # This is done in the forward(...) function\n",
    "    # Create a fully connected layer followed by softmax to interpet the output of the neural network as confidences for the classes\n",
    "    self.fully_connected  = torch.nn.Linear(in_features=4*4*48, out_features=10)  # tensor of length 10\n",
    "    self.softmax\t\t  = torch.nn.LogSoftmax(dim=1) # tensor of length 10, but entries are interpreted as probabilities\n",
    "\n",
    "  def predict(self, input):\n",
    "    # Do a forward pass to get a 1x10 tensor of class predcitions \n",
    "    x = self.forward( input )\n",
    "    # The final layer is LogSoftmax(...), so just use argmax to get the prediction\n",
    "    x = torch.argmax( x, dim=1 )\n",
    "    return x\n",
    "\n",
    "  def forward(self, input):\n",
    "    x = self.conv1( input )\n",
    "    x = self.bn1( x )\n",
    "    x = torch.nn.functional.relu6( x )\n",
    "    x = self.maxpool1( x )\n",
    "\n",
    "    x = self.conv2( x )\n",
    "    x = self.bn2( x )\n",
    "    x = torch.nn.functional.relu6( x )\n",
    "    x = self.maxpool2( x )\n",
    "\n",
    "    x = self.conv3( x )\n",
    "    x = self.bn3( x )\n",
    "    x = torch.nn.functional.relu6( x )\n",
    "\n",
    "    x = self.conv4( x )\n",
    "    x = self.bn4( x )\n",
    "    x = torch.nn.functional.relu6( x )\n",
    "\n",
    "    x = self.conv5( x )\n",
    "    x = self.bn5( x )\n",
    "    x = torch.nn.functional.relu6( x )\n",
    "\n",
    "    ### Automatically infer batch size\n",
    "    x = x.view(-1, 4*4*48 )\n",
    "    x = self.fully_connected( x )\n",
    "    x = self.softmax( x )\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Input and Inference Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Helper functions for inference timing\n",
    "###\n",
    "def StartInferenceTiming( device : torch.device ):\n",
    "    return time.time_ns()\n",
    "\n",
    "def StopInferenceTiming( start_time_ns : int, device : torch.device, ):\n",
    "    if device == torch.device('cuda'):\n",
    "        ### Synchronize before recording time if we are using GPU\n",
    "        torch.cuda.current_stream(device).synchronize()\n",
    "    ### Get duration\n",
    "    duration = time.time_ns() - start_time_ns\n",
    "    ### Return\n",
    "    return duration\n",
    "\n",
    "def TorchDeviceToText( device : torch.device ):\n",
    "    return 'CPU' if device == torch.device('cpu') else 'GPU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to process 1600 images on GPU device\n",
      "Throughput on GPU: 9386.966548958018 images/s\n",
      "Average Inference Time on GPU: 0.00010653068749999999 s/image\n"
     ]
    }
   ],
   "source": [
    "### Create an instance of our model\n",
    "model = MNIST_CNN().to(device)\n",
    "\n",
    "### Generate a couple dummy images and compute inference time\n",
    "batch_size              = 16\n",
    "number_of_image_batches = 100\n",
    "number_of_images        = batch_size * number_of_image_batches\n",
    "### Print number of images we are trying to process\n",
    "print('Attempting to process {} images on {} device'.format(number_of_images, TorchDeviceToText(device)))\n",
    "\n",
    "### Start timing\n",
    "start_time_ns = StartInferenceTiming(device)\n",
    "### Pass random inputs through the model\n",
    "for k in range(number_of_image_batches):\n",
    "    ### Generate a dummy input in the same shape as an MNIST image (28 x 28)\n",
    "    dummy_input = torch.randn(size=(batch_size, 1, 28, 28), device=device)\n",
    "    ### Pass through the model\n",
    "    forward_pass = model( dummy_input )\n",
    "### End timing\n",
    "duration_ns = StopInferenceTiming(start_time_ns, device)\n",
    "### Report throughput (image/s) and inference time (s/image)\n",
    "throughput          = number_of_images / ( duration_ns / 1000000000.0)\n",
    "avg_inference_time  = 1.0 / throughput\n",
    "\n",
    "print('Throughput on {}: {} images/s'.format(TorchDeviceToText(device), throughput))\n",
    "print('Average Inference Time on {}: {} s/image'.format(TorchDeviceToText(device), avg_inference_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('neliopou')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4a0635ff34eea32f215fe1d68280c4ff0f212cd67f96cd47d05854587dfda6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
